import os
import json
import logging
from datetime import datetime
from typing import List, Tuple, Optional
from core.config import Config
from llm.deepseek import DeepSeekClient

class AIReportGenerator:
    """å¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆè¯»å–è®¢é˜…åŸå§‹æ•°æ®ï¼Œç”ŸæˆAIæ€»ç»“ï¼‰"""
    def __init__(self, config: Config, deepseek_api_key: Optional[str]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.raw_data_dir = config.get("subscription.raw_data_dir", "data/raw_subscription_data")
        self.report_output_dir = config.get("report.output_dir", "ai_reports")
        os.makedirs(self.report_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–å¤§æ¨¡å‹å®¢æˆ·ç«¯
        self.deepseek_client = DeepSeekClient(
            api_key=deepseek_api_key,
            config=config
        ) if deepseek_api_key else None

    def load_subscription_raw_data(self, sub_id: Optional[int] = None) -> List[dict]:
        """åŠ è½½è®¢é˜…åŸå§‹æ•°æ®ï¼ˆå¯é€‰è¿‡æ»¤è®¢é˜…IDï¼‰"""
        raw_data_list = []
        if not os.path.exists(self.raw_data_dir):
            return raw_data_list
        
        # éå†æ‰€æœ‰åŸå§‹æ•°æ®æ–‡ä»¶
        for filename in os.listdir(self.raw_data_dir):
            if not filename.endswith("_raw.json"):
                continue
            file_path = os.path.join(self.raw_data_dir, filename)
            
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                # è¿‡æ»¤è®¢é˜…IDï¼ˆå¦‚æœæŒ‡å®šï¼‰
                if sub_id and data["subscription_id"] != sub_id:
                    continue
                raw_data_list.append(data)
            except Exception as e:
                self.logger.error(f"åŠ è½½åŸå§‹æ•°æ® {filename} å¤±è´¥: {str(e)}")
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
        return sorted(raw_data_list, key=lambda x: x["generated_at"], reverse=True)

    def generate_single_raw_report(self, raw_data: dict) -> Tuple[bool, str, Optional[str]]:
        """åŸºäºå•æ¡åŸå§‹æ•°æ®ç”ŸæˆAIæ€»ç»“æŠ¥å‘Š"""
        if not self.deepseek_client:
            return False, "æœªé…ç½®DeepSeek API Keyï¼Œæ— æ³•ç”ŸæˆAIæ€»ç»“", None
        
        try:
            # 1. æå–åŸå§‹æ•°æ®
            sub_id = raw_data["subscription_id"]
            repo_full_name = raw_data["repo_full_name"]
            time_range = raw_data["time_range"]
            repo_info = raw_data["data"]["repo_info"]
            releases = raw_data["data"]["releases"]
            commits = raw_data["data"]["commits"]
            prs = raw_data["data"]["pull_requests"]
            issues = raw_data["data"]["issues"]

            # 2. AIæ€»ç»“
            self.logger.info(f"ç”Ÿæˆè®¢é˜…ID {sub_id}ï¼ˆ{repo_full_name}ï¼‰çš„AIæ€»ç»“...")
            summaries = {
                "releases": self.deepseek_client.summarize_releases(releases),
                "commits": self.deepseek_client.summarize_commits(commits),
                "issues_prs": self.deepseek_client.summarize_issues_prs(issues, prs)
            }

            # 3. ç”ŸæˆMarkdownå†…å®¹
            markdown_content = self._format_markdown(
                repo_info=repo_info,
                time_range=time_range,
                summaries=summaries,
                raw_data=raw_data["data"]
            )

            # 4. ä¿å­˜æŠ¥å‘Š
            start_date = datetime.fromisoformat(time_range["start"]).strftime("%Y%m%d")
            safe_repo_name = repo_full_name.replace("/", "_")
            report_filename = f"{start_date}_sub{sub_id}_{safe_repo_name}_ai_report.md"
            report_path = os.path.join(self.report_output_dir, report_filename)

            with open(report_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)

            return True, f"æŠ¥å‘Šç”ŸæˆæˆåŠŸ", report_path
        except Exception as e:
            return False, f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", None

    def generate_subscription_report(self, sub_id: int) -> Tuple[bool, str, Optional[str]]:
        """ç”ŸæˆæŒ‡å®šè®¢é˜…IDçš„æœ€æ–°æŠ¥å‘Š"""
        raw_data_list = self.load_subscription_raw_data(sub_id)
        if not raw_data_list:
            return False, f"æœªæ‰¾åˆ°è®¢é˜…ID {sub_id} çš„åŸå§‹æ•°æ®", None
        
        # å¤„ç†æœ€æ–°çš„ä¸€æ¡åŸå§‹æ•°æ®
        latest_raw_data = raw_data_list[0]
        return self.generate_single_raw_report(latest_raw_data)

    def generate_all_reports(self) -> Tuple[int, int, List[str]]:
        """ç”Ÿæˆæ‰€æœ‰æœªå¤„ç†çš„åŸå§‹æ•°æ®æŠ¥å‘Šï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰"""
        raw_data_list = self.load_subscription_raw_data()
        if not raw_data_list:
            return 0, 0, []
        
        success_count = 0
        report_paths = []
        for raw_data in raw_data_list:
            # æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦å·²å­˜åœ¨
            start_date = datetime.fromisoformat(raw_data["time_range"]["start"]).strftime("%Y%m%d")
            sub_id = raw_data["subscription_id"]
            safe_repo_name = raw_data["repo_full_name"].replace("/", "_")
            report_filename = f"{start_date}_sub{sub_id}_{safe_repo_name}_ai_report.md"
            report_path = os.path.join(self.report_output_dir, report_filename)
            
            if os.path.exists(report_path):
                self.logger.info(f"æŠ¥å‘Šå·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š{report_filename}")
                continue
            
            # ç”ŸæˆæŠ¥å‘Š
            success, msg, path = self.generate_single_raw_report(raw_data)
            if success and path:
                success_count += 1
                report_paths.append(path)
        
        return success_count, len(raw_data_list), report_paths

    def _format_markdown(self, repo_info: dict, time_range: dict, summaries: dict, raw_data: dict) -> str:
        """æ ¼å¼åŒ–MarkdownæŠ¥å‘Šå†…å®¹"""
        generated_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        start_time = datetime.fromisoformat(time_range["start"]).strftime("%Y-%m-%d %H:%M")
        end_time = datetime.fromisoformat(time_range["end"]).strftime("%Y-%m-%d %H:%M")

        # æŠ¥å‘Šå¤´éƒ¨
        md = [
            f"# ğŸ¤– GitHubè®¢é˜…AIæ€»ç»“æŠ¥å‘Š",
            f"**ä»“åº“**: {repo_info.get('full_name', 'æœªçŸ¥')} [{repo_info.get('html_url', '')}]({repo_info.get('html_url', '')})",
            f"**è®¢é˜…ID**: {raw_data.get('subscription_id', 'æœªçŸ¥')}",
            f"**æ—¶é—´èŒƒå›´**: {start_time} ~ {end_time}",
            f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {generated_at}",
            "",
            "---",
            "",
            "## ğŸ“Š ä»“åº“åŸºæœ¬ä¿¡æ¯",
            f"- åç§°: {repo_info.get('name', 'æœªçŸ¥')}",
            f"- æè¿°: {repo_info.get('description', 'æ— æè¿°')}",
            f"- æ˜Ÿçº§: {repo_info.get('stargazers_count', 0)} â­",
            f"- åˆ†æ”¯: {repo_info.get('forks_count', 0)} ğŸ´",
            f"- æœ€åæ›´æ–°: {repo_info.get('updated_at', 'æœªçŸ¥')[:10]}",
            "",
            "---",
            "",
            "## ğŸ“ AIæ™ºèƒ½æ€»ç»“",
        ]

        # å„æ¨¡å—æ€»ç»“
        md.extend([
            "### ğŸ”– å‘å¸ƒæ€»ç»“",
            summaries["releases"],
            "",
            "### ğŸ’» å¼€å‘æäº¤æ€»ç»“",
            summaries["commits"],
            "",
            "### ğŸ“¢ ç¤¾åŒºæ´»åŠ¨æ€»ç»“ï¼ˆIssues/PRï¼‰",
            summaries["issues_prs"],
            "",
            "---",
            "",
        ])

        # åŸå§‹æ•°æ®é¢„è§ˆ
        md.append("## ğŸ” åŸå§‹æ•°æ®é¢„è§ˆï¼ˆå‰5æ¡ï¼‰")
        
        # å‘å¸ƒé¢„è§ˆ
        if raw_data["releases"]:
            md.extend([
                "### æœ€æ–°å‘å¸ƒ",
                "| ç‰ˆæœ¬ | å‘å¸ƒæ—¶é—´ | æ ‡é¢˜ |",
                "|------|----------|------|",
            ])
            for r in raw_data["releases"][:5]:
                md.append(f"| {r.get('tag_name', 'æœªçŸ¥')} | {r.get('published_at', '')[:10]} | {r.get('name', '')[:50]} |")
            md.append("")
        
        # æäº¤é¢„è§ˆ
        if raw_data["commits"]:
            md.extend([
                "### æœ€è¿‘æäº¤",
                "| å“ˆå¸Œ | ä½œè€… | æ—¶é—´ | ä¿¡æ¯ |",
                "|------|------|------|------|",
            ])
            for c in raw_data["commits"][:5]:
                sha = c.get('sha', '')[:7]
                msg = c.get('commit', {}).get('message', '').splitlines()[0][:50]
                md.append(f"| {sha} | {c.get('author', {}).get('login', 'æœªçŸ¥')} | {c.get('commit', {}).get('committer', {}).get('date', '')[:10]} | {msg} |")
            md.append("")

        return "\n".join(md)